### 意见性分享
- **机器人需要触觉吗？**

  #####   Srinath Sridhar:

  **For someone so successful in the high-tech business, [@elonmusk](https://twitter.com/elonmusk) is surprisingly naive about AI/robots. We are decades away from building robots with the capabilities he claims in his prototype (human-level hands by 2022? good luck with that).**

    **Michael Black**: People typically underestimate the importance of haptics. Without touch, you don’t have a hand. We still don’t have the sensors to recreate human-level touch. Then for real human-level hand control, you need vision. We’ve seen the overly optimistic claims about that before.

    **Michael Black**: To understand why vision is not enough for human-level dexterity, the famous Johannson experiment is illustrative. You can live a happy and productive life without vision. You can't live without touch.  [https://youtube.com/watch?v=HH6QD0MgqDQ](https://t.co/duwU9xdG77?amp=1)

  reference:https://twitter.com/drsrinathsridha/status/1428775742943412233


***
### 课程和报告分享

#### SIGGRAPH 2021 Course《Advances in Neural Rendering》

##### original twitter link（from @JustusThies ）：
https://twitter.com/JustusThies/status/1424403610461421568

##### webpage：
https://www.neuralrender.com/

##### location & time：
You need to be registered to the conference in order to access the lectures. live Q&A session will be held on August 9th, 2021, 9:00 PT

##### content
This course covers the advances in neural rendering over the last year. We will first cover the fundamentals of machine learning and computer graphics relevant for neural rendering. Next, we will present state of the art techniques for the many important neural rendering methods for applications such as novel view synthesis, semantic photo manipulation, facial and body reenactment, relighting, free-viewpoint video, and the creation of photo-realistic avatars for virtual and augmented reality telepresence. Finally, we will conclude with a discussion on the ethical implications of this technology and open research problems.![Image](https://pbs.twimg.com/media/E8R_BFBXMAMwJYl?format=jpg&name=900x900)

**包含了和神经渲染有关的机器学习和图形学基础知识，同时也介绍了神经渲染技术的一些应用。**


***
#### 《Geometric Deep Learing》（GDL）
##### original twitter link（from @PetarV_93 ）：
https://twitter.com/PetarV_93/status/1424456886015889415

##### webpage：
https://geometricdeeplearning.com/lectures/

##### video：
https://www.youtube.com/playlist?list=PLn2-dEmQeTfQ8YVuHBOvAhUlnIPYxkeu3

##### arxiv：
https://arxiv.org/abs/2104.13478

##### content：
As part of the African Master’s in Machine Intelligence (AMMI 2021), we have delivered a course on Geometric Deep Learing (GDL100), which closely follows the contents of our GDL proto-book. We make all materials and artefacts from this course publicly available, as companion material for our proto-book, as well as a way to dive deeper into some of the contents for future iterations of the book.![Image](https://pbs.twimg.com/media/E8SvKLhXsAY3RtG?format=jpg&name=900x900)

**介绍了Geometric Deep Learing的相关知识，提供了视频和slides。**



### 成果推荐及讨论

  
- ##### [Brian](https://twitter.com/bhsavery/status/1427732705806929923)
  **Implemented @Peter_shirley's "Ray Tracing in One Weekend" in pure #python that can execute on the GPU (via Metal, Vulkan, CUDA) using a package called "Taichi".** Was surprisingly easy and runs fast, these higher level languages for GPU could be the future!
  
  github: https://github.com/bsavery/ray-tracing-one-weekend-taichi.
  
  - **erithacus:** I'm planning on having a go at it in swift at some point. Will be a big challenge for me (especially as I’ll have to learn a bit of C++ to interpret the course), but I think it will be fun.

  **评述：** 基于Taichi编程语言的光追（Ray Tracing）项目。
